}
dim(df.train.list[[1]])
col(df.train.list[[1]])
ncol(df.train.list[[1]])
df.names1
df.names1[1]
index.names1
index.names1[1]
df.names1 <- df.names[1]
index.names1 = index.names#[5]
results = data.frame(stringsAsFactors=FALSE)
df <- df.names1[1]
train <- df.train.list[[df]]
test <- df.test.list[[df]]
i <- index.names1[1]
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
train
test
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions = c()
# Para cada observación, obtenemos la predicción
for (i in 1:nrow(x_pred)){
#print(i)
neighbors = nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred = knn_prediction(x_fit[neighbors[[1]], ], neighbors[[2]])
}else{
pred = knn_prediction(x_fit[neighbors[[1]], ])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred = knn(x_fit, x_pred[i,], k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] = pred
}
return(predictions)
}
nrow(df.test.list[[1]])
nrow(df.test.list[[2]])
nrow(df.test.list[[3]])
df.names1 <- df.names[1]
index.names1 = index.names#[5]
results = data.frame(stringsAsFactors=FALSE)
df <- df.names1[1]
train <- df.train.list[[df]]
test <- df.test.list[[df]]
i <- index.names1[1]
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
ncol(df.test.list[[1]])
df.test.list[[1]][,-1]
View(df.test.list[[1]][,-1])
class(df.test.list[[1]][,-1])
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k, FUN = func)
ncol(df.train.list[[1]][,-1])
ncol(df.test.list[[1]][1,-1])
dim(df.test.list[[1]][1,-1])
class(df.test.list[[1]][1,-1])
View(df.test.list[[1]][1,-1])
print(df.test.list[[1]][1,-1])
length(df.test.list[[1]][1,-1])
nearest_neighbors <- function(x, obs, k, FUN, p=NULL){
"
x:    matriz de nxm donde cada fila es una serie de tiempo de referencia. Hay n
series de longitud m.
obs:  matriz de 1Xm que representa a una serie de longitud m la cual queremos
clasificar comparando con las series de referencia.
k:    nro de vecinos más cercanos.
FUN:  medida de distancia.
p:    algún parámetro extra de la función FUN
"
# Checkeamos si el nro de observaciones es igual
if (dim(x)[2] != length(obs)){stop('Las series deben tener la misma longitud')}
# Calulculamos la distancia, considerando p por Minkowski
if(is.null(p)){
dist = parApply(cl, x, 1, FUN, obs)
}else{
dist = parApply(cl, x, 1, FUN, obs, p)
}
# Encontrar el vecino más cercno
distances = sort(dist)[1:k]
neighbor_ind = which(dist %in% distances)
if(length(neighbor_ind) != k){
warning(
paste("Varias variables con igual distancia. Se usó k:", length(neighbor_ind))
)
}
ret = list(neighbor_ind, distances) # OJO! las dos listas no son correspondientes!
return(ret)
}
df.names1 <- df.names[1]
index.names1 = index.names#[5]
results = data.frame(stringsAsFactors=FALSE)
df <- df.names1[1]
train <- df.train.list[[df]]
test <- df.test.list[[df]]
i <- index.names1[1]
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k, FUN = func)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k, FUN=EuclideanDistance)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k=1, FUN=EuclideanDistance)
df.names1 = df.names#[10]
index.names1 = index.names#[5]
results = data.frame(stringsAsFactors=FALSE)
#invisible(lapply(df.names, function(df){
for (df in df.names1) {
train <- df.train.list[[df]]
test <- df.test.list[[df]]
for (i in index.names1) {
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
predicciones <- factor(predicciones, levels=levels(as.factor(test[,1])))
ConfMat <- confusionMatrix(as.factor(predicciones), as.factor(test[,1]))
toappend <- cbind(df, i, ConfMat$overall[1])
colnames(toappend) <- c("Dataset", "Index", "Accuracy")
results <<- rbind(results, toappend)
print(paste(df,i))
}
}
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k, FUN=EuclideanDistance)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k=3, FUN=EuclideanDistance)
nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k=1, FUN=EuclideanDistance)
prueba <- nearest_neighbors(df.train.list[[1]][,-1], df.test.list[[1]][1,-1], k=1, FUN=EuclideanDistance)
prueba[[1]]
df.train.list(prueba[[1]])
df.train.list[[1]](prueba[[1]])
df.train.list[[1]][prueba[[1]]]
df.train.list[[1]][prueba[[1]],]
prueba <- nearest_neighbors(train[,-1], test[1,-1], k=3, FUN=EuclideanDistance); prueba
pred_prueba = knn_prediction(train[prueba[[1]], ])
prueba <- nearest_neighbors(train[,-1], test[1,-1], k=3, FUN=EuclideanDistance); prueba
pred_prueba = knn_prediction(train[prueba[[1]], ]); pred_prueba
knn(train, test, k=3, FUN=EuclideanDistance)
```{r}
knn(train, test, k=3, fun=EuclideanDistance)
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions = c()
# Para cada observación, obtenemos la predicción
for (i in 1:dim(x_pred)[1]){
#print(i)
neighbors = nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred = knn_prediction(x_fit[neighbors[[1]], ], neighbors[[2]])
}else{
pred = knn_prediction(x_fit[neighbors[[1]], ])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred = knn(x_fit, x_pred[i,], k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] = pred
}
return(predictions)
}
knn(train, test, k=3, fun=EuclideanDistance)
class(tesy)
class(test)
dim(test)
dim(test)[1]
dim(train)[1]
dim(train)[2]
for (i in 1:dim(test)[]) {
print(i)
}
for (i in 1:dim(test)[2]) {
print(i)
}
for (i in 1:dim(test)[1]) {
print(i)
}
View(train[,-1])
View(test[1,-1])
length(test[1,-1])
prueba
prueba[1]
train[prueba[1]]
train[prueba[[1]]
]
train[prueba[[1]]]
train[prueba[[1]],]
train[prueba[[1]],][,1]
table(train[prueba[[1]],][,1])
grupos_prueba <- table(train[prueba[[1]],][,1])
names(grupos_prueba[grupos_prueba == max(grupos_prueba)])
knn(train, test, k=1, func = EuclideanDistance)
train[prueba[[1]],][,1]
train[prueba[[1]],1]
table(train[prueba[[1]],1])
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions = c()
# Para cada observación, obtenemos la predicción
for (i in 1:dim(x_pred)[1]){
#print(i)
neighbors = nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred = knn_prediction(x_fit[neighbors[[1]], 1], neighbors[[2]])
}else{
pred = knn_prediction(x_fit[neighbors[[1]], 1])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred = knn(x_fit, x_pred[i,], k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] = pred
}
return(predictions)
}
# Predicción del algoritmo KNN
knn_prediction <- function(x){
groups = table(x)
pred = names(groups[groups == max(groups)])
return(pred)
}
knn(train, test, k=3, func = EuclideanDistance)
x_pred
dim(test)
dim(test)[1]
dim(test)[2]
class(train)
class(test)
dim(test)
length(test)
nrow(test)
nrow(test)
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions = c()
# Para cada observación, obtenemos la predicción
for (i in 1:dim(x_pred)[1]){
print(i)
neighbors = nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred = knn_prediction(x_fit[neighbors[[1]], 1], neighbors[[2]])
}else{
pred = knn_prediction(x_fit[neighbors[[1]], 1])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred = knn(x_fit, x_pred[i,], k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] = pred
}
return(predictions)
}
knn(train, test, 3, EuclideanDistance)
i
test[1,]
length(test[1,])
dim(test[1,])
dim(as.matrix(test[1,]))
dim(t(as.matrix(test[1,])))
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions = c()
# Para cada observación, obtenemos la predicción
for (i in 1:dim(x_pred)[1]){
print(i)
neighbors = nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred = knn_prediction(x_fit[neighbors[[1]], 1], neighbors[[2]])
}else{
pred = knn_prediction(x_fit[neighbors[[1]], 1])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred = knn(x_fit, t(as.matrix(x_pred[i,])), k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] = pred
}
return(predictions)
}
knn(train, test, 3, EuclideanDistance)
nearest_neighbors <- function(x, obs, k, FUN, p=NULL){
"
x:    matriz de nxm donde cada fila es una serie de tiempo de referencia. Hay n
series de longitud m.
obs:  matriz de 1Xm que representa a una serie de longitud m la cual queremos
clasificar comparando con las series de referencia.
k:    nro de vecinos más cercanos.
FUN:  medida de distancia.
p:    algún parámetro extra de la función FUN
"
# Checkeamos si el nro de observaciones es igual
if (dim(x)[2] != length(obs)){stop('Las series deben tener la misma longitud')}
# Calulculamos la distancia, considerando p por Minkowski
if(is.null(p)){
dist <- parApply(cl, x, 1, FUN, obs)
}else{
dist <- parApply(cl, x, 1, FUN, obs, p)
}
# Encontrar el vecino más cercno
distances <- sort(dist)[1:k]
neighbor_ind <- which(dist %in% distances)
if(length(neighbor_ind) != k){
warning(
paste("Varias variables con igual distancia. Se usó k:", length(neighbor_ind))
)
}
ret <- list(neighbor_ind, distances) # OJO! las dos listas no son correspondientes!
return(ret)
}
# Predicción del algoritmo KNN
knn_prediction <- function(x){
groups <- table(x)
pred <- names(groups[groups == max(groups)])
return(pred)
}
# Predicción para varias series
knn <- function(x_fit, x_pred, k,
func = EuclideanDistance, weighted_pred = F, p = NULL){
"
x_fi:   dataframe con series de referencia (by row) y primera columna como etiqueta de clase
x_pred: dataframe con series a clasificar (by row) y primera columna como etiqueta de clase
k:      nro de vecinos más cercanos
func:   medida de distancia
weighted_pred:  no sé que es!
p:      parámetro extra de la func medida de distancia
"
# Inicializamos las predicciones
predictions <- c()
# Para cada observación, obtenemos la predicción
for (i in 1:dim(x_pred)[1]){
print(i)
neighbors <- nearest_neighbors(x_fit[,-1],
x_pred[i,-1], k, FUN = func)
if (weighted_pred){
pred <- knn_prediction(x_fit[neighbors[[1]], 1], neighbors[[2]])
}else{
pred <- knn_prediction(x_fit[neighbors[[1]], 1])
}
# Si hay más de 1 clase predicha, hacer una prediccion con k más 1
if(length(pred) > 1){
pred <- knn(x_fit, t(as.matrix(x_pred[i,])), k=k+1,
func = func, weighted_pred = weighted_pred, p==p)
}
predictions[i] <- pred
}
return(predictions)
}
Chebyshev.Measure <- function(s1, s2) {return(chebyshev(s1, s2, testNA = F))}
ERP.Measure <- function(s1, s2) {return(ERPDistance(s1, s2, .1))}
EDR.Measure <- function(s1, s2) {return(EDRDistance(s1, s2, .1))}
index.list <- list(Manhattan =TSdist::ManhattanDistance, #1
Euclidean = TSdist::EuclideanDistance, #2
Chebyshev = Chebyshev.Measure, #3
MSE = Metrics::mse, #4
Frechet = Frechets.Measure, #5
DTW = TSdist::DTWDistance, #6
ERP = ERP.Measure, #7
EDR = EDR.Measure, #8
Fourier = TSdist::FourierDistance, #9
Pearson = Pearsons.Measure, #10
CORT = CORT.Measure, #11
Chouakria = TSdist::CortDistance, #12
LCSS = LCSS.Measure) #13
index.names <- names(index.list)
knn(train, test, k=1, fun=EuclideanDistance)
df.names1 <- df.names[1]
index.names1 = index.names[5]
results = data.frame(stringsAsFactors=FALSE)
df <- df.names1[1]
train <- df.train.list[[df]]
test <- df.test.list[[df]]
i <- index.names1[1]
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
predicciones <- factor(predicciones, levels=levels(as.factor(test[,1])))
ConfMat <- confusionMatrix(as.factor(predicciones), as.factor(test[,1]))
toappend <- cbind(df, i, ConfMat$overall[1])
colnames(toappend) <- c("Dataset", "Index", "Accuracy")
results <<- rbind(results, toappend)
print(paste(df,i))
df.names1 = df.names[10]
index.names1 = index.names[5]
results = data.frame(stringsAsFactors=FALSE)
#invisible(lapply(df.names, function(df){
for (df in df.names1) {
train <- df.train.list[[df]]
test <- df.test.list[[df]]
for (i in index.names1) {
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
predicciones <- factor(predicciones, levels=levels(as.factor(test[,1])))
ConfMat <- confusionMatrix(as.factor(predicciones), as.factor(test[,1]))
toappend <- cbind(df, i, ConfMat$overall[1])
colnames(toappend) <- c("Dataset", "Index", "Accuracy")
results <<- rbind(results, toappend)
print(paste(df,i))
}
}
i
df
length(df.names)
df.names1 = df.names[4]
index.names1 = index.names[5]
results = data.frame(stringsAsFactors=FALSE)
#invisible(lapply(df.names, function(df){
for (df in df.names1) {
train <- df.train.list[[df]]
test <- df.test.list[[df]]
for (i in index.names1) {
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
predicciones <- factor(predicciones, levels=levels(as.factor(test[,1])))
ConfMat <- confusionMatrix(as.factor(predicciones), as.factor(test[,1]))
toappend <- cbind(df, i, ConfMat$overall[1])
colnames(toappend) <- c("Dataset", "Index", "Accuracy")
results <<- rbind(results, toappend)
print(paste(df,i))
}
}
#}))
df.names1 = df.names[4]
index.names1 = index.names
results = data.frame(stringsAsFactors=FALSE)
#invisible(lapply(df.names, function(df){
for (df in df.names1) {
train <- df.train.list[[df]]
test <- df.test.list[[df]]
for (i in index.names1) {
funcion <- index.list[[i]]
predicciones <- knn(train, test, k=1, func=funcion)
predicciones <- factor(predicciones, levels=levels(as.factor(test[,1])))
ConfMat <- confusionMatrix(as.factor(predicciones), as.factor(test[,1]))
toappend <- cbind(df, i, ConfMat$overall[1])
colnames(toappend) <- c("Dataset", "Index", "Accuracy")
results <<- rbind(results, toappend)
print(paste(df,i))
}
}
stopCluster(cl)
unique(results$Dataset)
results[order(results$Accuracy, decreasing = T),]
ggplot(results, aes(x=as.factor(Dataset), y=as.numeric(Accuracy),fill=Index))+
geom_bar(stat="identity", position=position_dodge())+
geom_text(aes(label=round(as.numeric(Accuracy),2)), vjust=.18, color="black",
position = position_dodge(0.9), size=2.5,angle = 90) +
facet_grid( ~Dataset , scales="free")+
#facet_wrap(~Contaminación + Dataset)+
#theme(legend.position = 'none')+
#scale_x_continuous(breaks=seq(0,10,1))+
labs(title = "Accuracy")
library(roxygen2); # Read in the roxygen2 R package
roxygenise();      # Builds the help files
library(devtools);
load_all("."); # Working directory should be in the package SCC_R_package
